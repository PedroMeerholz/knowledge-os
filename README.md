---
title: Knowledge OS
emoji: üöÄ
colorFrom: blue
colorTo: indigo
sdk: docker
pinned: false
---

# Knowledge OS

Sistema pessoal de gest√£o de conhecimento constru√≠do com Python e NiceGUI.

## O Problema

Quem estuda por diferentes fontes -- livros, v√≠deos, artigos, podcasts, cursos -- acaba com anotacoes espalhadas em cadernos, apps e arquivos soltos. Com o tempo, fica dif√≠cil:

- **Reencontrar** uma anota√ß√£o espec√≠fica feita meses atr√°s
- **Saber de onde veio** cada informa√ß√£o (qual livro, qual v√≠deo, qual autor)
- **Enxergar padr√µes** nos proprios estudos (que tipo de fonte voc√™ mais consome? quais temas domina?)
- **Descobrir lacunas** e receber sugest√µes de novas fontes para estudar

## A Solucao (O que o sistema faz)

O Knowledge OS centraliza todas as suas anotacoes em um √∫nico lugar com metadados ricos (fonte, autor, tipo, tags) e oferece ferramentas visuais para explorar e consultar sua base de conhecimento.

### Funcionalidades

| P√°gina | Descri√ß√£o |
|--------|-----------|
| **Nova Nota** | Formul√°rio para criar notas com t√≠tulo, conte√∫do, tipo de fonte, nome da fonte, autor e tags |
| **Banco de Notas** | Lista todas as notas com busca por texto e filtro por tipo de fonte. Permite editar e excluir notas |
| **Gerenciar Tags** | Cria√ß√£o e exclus√£o de tags para categorizar suas notas |
| **Mapa de Fontes** | Gr√°ficos (rosca e barras) mostrando a distribui√ß√£o dos tipos de fontes e tabela com todas as fontes utilizadas |
| **Chat & Recomenda√ß√µes** | Interface dividida: chat para consultar suas notas (lado esquerdo) e painel de recomenda√ß√µes de fontes geradas com base na sua pergunta (lado direito). M√≥dulo de IA pendente ‚Äî conte√∫do placeholder por enquanto |
| **Relat√≥rios** | Gerar relat√≥rios com IA com base nas notas cadastradas pelo usu√°rio. O sistema requer pelo menos 10 notas por √°rea de conhecimento para gerar o relat√≥rio |

### Stack T√©cnica

- **Interface**: [NiceGUI](https://nicegui.io/) (Python, baseado em Vue.js/Quasar/FastAPI)
- **Banco de dados**: Arquivos JSON locais
- **Gr√°ficos**: Apache ECharts (via NiceGUI)

## Utiliza√ß√£o de Agentes de IA para Cria√ß√£o da Interface Gr√°fica

**Escolhas de design**
| Pergunta | Resposta |
| -------- | -------- |
| Por que essa arquitetura? | Optei por estas tecnologias por ter maior conhecimento t√©cnico e experi√™ncia. Dessa forma, caso fosse necess√°rio a interven√ß√£o manual no c√≥digo, a manuten√ß√£o seria mais eficaz | 
| Por que esses componentes de UI? | A escolha dos componentes foi realizada com base na premissa de manter o sistema com uma interface gr√°fica minimalista e intuitiva | 
| Que alternativas foram consideradas? | Considerei utilizar outros frameworks para criar a interface gr√°fica, como React e Vue.js. Por√©m, para manter todo o projeto em linguagem Python, optei por usar a biblioteca NiceGUI |

**O que funcionou?**
| Pergunta | Resposta |
| -------- | -------- |
| Quais partes o agente de codifica√ß√£o gerou bem? | O agente fez uma boa codifica√ß√£o ao criar as funcionalidades da interface gr√°fica |
| Onde a experi√™ncia foi positiva? | Desenvolvimento r√°pido e preciso |
| Exemplos espec√≠ficos de prompts que deram bons resultados | Merge the chat page and recomendation page. On the left side, I want the chat and in the right side I want the recomendation system. Then, refactor the recomendation to be connected with the chat. When the user ask a question, the recommendation system search in web for knowledgements fonts to complement the user question. Each recommendation needs to have a short summary to help user to understand why the recommendation is available for him. |

**Evid√™ncia de Prompt (/data/readme)**

![Prompt inicial](/data/readme/Notes%20Claude%20Evidence.png "Optional title")

**O que n√£o funcionou** 
| Pergunta | Resposta |
| -------- | -------- |
| Onde o agente falhou? | O agente apresentou alguns problemas de entendimento a respeito da constru√ß√£o de alguns elementos da interface gr√°fica, precisando refazer alguns componentes eventualmente | 
| O que precisou de interven√ß√£o manual? | Os nomes das p√°ginas precisaram passar por uma revis√£o ap√≥s a tradu√ß√£o para PT-BR, j√° que algumas n√£o foram traduzidas corretamente ou poderiam recber nomes mais adequados ao contexto do sistema | 
| Quais limita√ß√µes foram encontradas? O que seria feito diferente? | Acredito que prompts mais detalhados no momento da cria√ß√£o da interface gr√°fica poderiam ter ajudado o modelo a desempenhar melhor neste momento |

## Frameworks e Arquitetura do Sistema
**1. Escolha de framework: Por que Langchain?**

O framework me permite integrar com v√°rios modelos diferentes, criar o RAG e as ferramentas facilmente, eliminando a necessidade de criar tudo do zero. Utilizar o SDK da empresa fornecedora do modelo, iria restingir o projeto ao uso dos modelos desta empresa e ainda assim seria necess√°rio de uma biblioteca que ajudasse na constru√ß√£o do RAG, para reduzir a quantidade e a complexidade do c√≥digo.

**2. Conte√∫do, estrutura e estrat√©gias de prompt**

Todos os prompts foram desenvolvidos separadamente, pensando no cen√°rio em que cada um deles seria utilizado. No entanto, a utiliza√ß√£o de tags para delimitar onde uma determinada informa√ß√£o relevante est√° contida, foi utilizada em mais de um prompt tendo em vista que isto pode vir a melhorar o desempenho do modelo.

**3. Par√¢metros do modelo: Por que modelos da OpenAI?**

Inicialmente os teste foram realizados de forma local com o modelo ministral-3:8b via Ollama. Este modelo apresentou capacidade de responder as perguntas de forma adequada e de fazer o uso correto das ferramentas. No entanto, por conta de restri√ß√µes do hardware local o modelo tinha um tempo de resposta muito alto. Em resumo, modelos mais simples poderiam ser utilizados desde que o tempo de resposta n√£o fosse um problema.

Dessa forma, visando diminuir o tempo de resposta, foi realizada a mudan√ßa para os modelos da OpenAI. O modelo usado para o chat foi o gpt-4o e para o guardrail, o modelo gpt-4o-mini.

Referente aos par√¢metros do modelo, foram utilizados os par√¢metros padr√£o, tendo em vista que apresentaram um resultado satisfat√≥rio durante os testes.

**4. Ferramentas disponibilizadas**

search_knowledge: Respons√°vel para encontrar e filtrar as informa√ß√µes dentro do banco vetorial.

**5. RAG**

Esta t√©cnica foi utilizada por conta das frequ√™ncia de atualiza√ß√£o dos dados. No sistema o usu√°rio pode cadastrar informa√ß√µes textuais sempre que achar necess√°rio, requerendo a necessidade de uma arquitetura que suporte mudan√ßas frequentes e radicais sem que o modelo utilizado perca precis√£o. Neste cen√°rio, realizar o fine-tuning de um modelo com pesos abertos n√£o faria sentido, pois como n√£o se tem previsibilidade do cont√∫do escrito pelo usu√°rio, n√£o seria poss√≠vel realizar uma boa otimiza√ß√£o deste modelo.

Para criar o banco de dados vetorial, foi utilizada a biblioteca FAISS. Apesar do ChromaDB ser uma boa op√ß√£o e possuir filtro de metadados de forma nativa (o que reduziria a complexidade do c√≥digo), enfrentei problemas de integra√ß√£o com a minha vers√£o do Python. Dessa forma, como o FAISS n√£o apresentou problemas de integra√ß√£o, optei por prosseguir com esta op√ß√£o.

**6. Guardrail**

Para tratar eventuais falhas do modelo de linguagem, onde traz informa√ß√µes irrelevantes ou sens√≠veis em suas respostas, foi criado um guardrail. Este guardrail √© um agente que recebe a pergunta do usu√°rio e a resposta do modelo e valida se a resposta est√° coerente com o que o usu√°rio pediu, assim como realiza algumas verifica√ß√µes de seguran√ßa.

## Proximos Passos

- Integracao com LLM + busca na web para Recomenda√ß√µes (analise da pergunta do usuario para sugerir fontes reais)
- Exportacao de notas (PDF, Markdown)
